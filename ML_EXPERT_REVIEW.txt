================================================================================
FMCG DEMAND FORECASTING SYSTEM - TECHNICAL REVIEW DOCUMENT
================================================================================
For ML Expert Review & Consultation
Date: December 2024
Project: Final Year - Supply & Demand Forecasting System

================================================================================
1. PROJECT OVERVIEW
================================================================================

GOAL: Build FMCG demand forecasting system achieving 35-40% WMAPE

BUSINESS REQUIREMENTS:
- Reduce stockouts by 25-30% for A/B-class SKUs
- Reduce excess inventory by 15%
- Improve forecast accuracy by 20-25% vs Excel baseline (~50% MAPE)
- Daily/weekly forecasts at SKU Ã— Location granularity

CURRENT STATUS:
âœ… Data pipeline working (1.7M rows, 84 features)
âœ… Stockout correction implemented
âœ… Feature engineering complete
âŒ Model performance: 76-77% WMAPE (Target: 35-40%)
âš ï¸  Promo model: 5.7% WMAPE (Excellent but suspicious)

================================================================================
2. DATA CHARACTERISTICS
================================================================================

DATASET SIZE:
- Raw data: 7.3M rows (2006-2015, 10 years)
- After cleaning: 1.7M rows
- Excluded: 5.6M fully censored rows (opening_stock=0)

GRANULARITY:
- SKU Ã— Location Ã— Date (daily)
- 100 SKUs across 8 categories
- 50 locations across 5 regions
- 2 channels: Modern Trade, General Trade

TARGET VARIABLE:
- Original: actual_demand (censored by stockouts)
- Corrected: true_demand (velocity-based imputation)
- Correction impact: +10-20% demand increase

DATA QUALITY ISSUES:
- Stockout censoring (partially censored: closing_stock=0, sales>0)
- Missing values (~5-10%)
- SKU code changes over time
- Inconsistent unit measurements

================================================================================
3. FEATURE ENGINEERING (84 FEATURES)
================================================================================

CATEGORY 1: TEMPORAL FEATURES (12)
â”œâ”€â”€ Calendar: day_of_week, month, quarter, year
â”œâ”€â”€ Binary: is_weekend, is_month_start, is_month_end
â”œâ”€â”€ Cyclical: day_of_week_sin/cos, month_sin/cos
â””â”€â”€ Derived: week_of_year, days_in_month

CATEGORY 2: LAG FEATURES (4)
â”œâ”€â”€ demand_lag_1          # Yesterday's demand
â”œâ”€â”€ demand_lag_7          # Last week's demand
â”œâ”€â”€ demand_rolling_7_mean # 7-day moving average
â””â”€â”€ demand_rolling_7_cv   # Coefficient of variation (volatility)

CATEGORY 3: PRICE/PROMO FEATURES (7)
â”œâ”€â”€ discount_depth        # (base_price - price) / base_price
â”œâ”€â”€ price_changed         # Binary: price changed vs last week
â”œâ”€â”€ promo_intensity_7d    # Rolling 7-day promo frequency
â”œâ”€â”€ price_volatility_30d  # 30-day price std dev
â”œâ”€â”€ price_to_base         # Current price / base price ratio
â”œâ”€â”€ promo_flag            # Explicit promotion indicator
â””â”€â”€ base_price            # Regular price (no discount)

CATEGORY 4: SKU FEATURES (10)
â”œâ”€â”€ Categorical: category, brand, segment, abc_class
â”œâ”€â”€ Numeric: base_price, pack_size, unit_price
â”œâ”€â”€ Lifecycle: birth_date, days_since_launch
â””â”€â”€ Binary: is_perishable

CATEGORY 5: LOCATION FEATURES (8)
â”œâ”€â”€ Categorical: region, city, channel
â”œâ”€â”€ Numeric: store_size, population_density
â”œâ”€â”€ Ordinal: urbanization_level, income_level
â””â”€â”€ Derived: competition_intensity

CATEGORY 6: EXTERNAL FEATURES (15)
â”œâ”€â”€ Festival (5): is_festival, festival_in_1d/3d/7d, festival_type
â”œâ”€â”€ Weather (6): avg_temp, min_temp, max_temp, precipitation, humidity, wind
â”‚   â””â”€â”€ GATED by category (only BEVERAGES, DAIRY, SNACKS)
â”œâ”€â”€ Shock (2): shock_demand_impact, shock_supply_impact
â””â”€â”€ Competitor (2): competitor_promo_intensity, competitor_price_pressure

CATEGORY 7: INTERACTION FEATURES (28)
â”œâ”€â”€ SKU Ã— Location interactions (auto-generated by LightGBM)
â”œâ”€â”€ Price Ã— Promo interactions
â”œâ”€â”€ Category Ã— Season interactions
â””â”€â”€ Lifecycle Ã— Seasonality

FEATURE SELECTION LOGIC:
- Excluded: Target, IDs, leaky columns (expected_demand, closing_stock, etc.)
- Included: All engineered features (84 total)
- Categorical encoding: Native LightGBM categorical support

================================================================================
4. STOCKOUT CORRECTION (CRITICAL COMPONENT)
================================================================================

PROBLEM:
When stockouts occur, observed demand is censored (lower than true demand).
Training on censored data causes systematic underprediction.

SOLUTION: Velocity-Based Imputation
```
velocity = 7-day rolling average of demand (before stockout)
velocity_capped = min(velocity, p95_velocity)  # Prevent promo inflation
true_demand = max(actual_demand, velocity_capped)
```

IMPLEMENTATION:
1. Sort by SKU Ã— Location Ã— Date
2. Calculate 7-day rolling velocity (shift=1, min_periods=3)
3. Cap velocity at p95 per SKU-location
4. Identify censored rows: stockout_flag=1 AND closing_stock=0 AND sales>0
5. Impute: true_demand = max(actual_demand, velocity_capped)
6. Exclude fully censored rows: opening_stock=0

IMPACT:
- Corrected: 135,435 partially censored rows
- Excluded: 5,598,566 fully censored rows
- Demand increase: +10-20% for corrected observations

VALIDATION:
âœ… Promo model uses true_demand (5.7% WMAPE - excellent)
âŒ Horizon models use true_demand but still fail (76-77% WMAPE)

================================================================================
5. MODEL ARCHITECTURES
================================================================================

OPTION 1: BASELINE MODEL (FMCGTrainer)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Architecture:
- Single LightGBM model
- Uses all 84 features
- Tweedie loss (variance_power=1.3)
- Early stopping on validation WMAPE

Hyperparameters:
- n_estimators: 5000
- learning_rate: 0.03
- num_leaves: 256
- max_depth: -1 (unlimited)
- subsample: 0.7
- colsample_bytree: 0.7
- min_child_weight: 500
- reg_lambda: 1.0

Train/Val/Test Split:
- Train: 70% (oldest data)
- Val: 15% (middle period)
- Test: 15% (most recent)
- Time-based split (no shuffling)

Expected Performance: 38-42% WMAPE


OPTION 2: ADVANCED MODELS (Current - BROKEN)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

A. HORIZON-SPECIFIC MODELS (HorizonTrainer)
   
   Philosophy: Different horizons need different features
   
   Short Horizon (1-7 days):
   - Additional lags: h_lag_1, h_lag_7, h_roll_7
   - Hyperparameters: lr=0.03, depth=8, leaves=96
   - Use case: Daily replenishment
   
   Mid Horizon (8-30 days):
   - Additional lags: h_lag_7, h_lag_14, h_roll_14
   - Hyperparameters: lr=0.025, depth=7, leaves=80
   - Use case: Weekly planning
   
   Long Horizon (31+ days):
   - Additional lags: h_lag_30, h_roll_30
   - Hyperparameters: lr=0.02, depth=6, leaves=64
   - Use case: Monthly production planning
   
   CURRENT ISSUE:
   - Creating horizon-specific lags but NOT using base 84 features
   - Training with only 3-4 features instead of 84+3
   - Result: 76-77% WMAPE (catastrophic failure)


B. PROMO UPLIFT MODEL (PromoUpliftTrainer)
   
   Philosophy: Separate base demand from promotional lift
   
   Baseline Model:
   - Trained ONLY on non-promo data (promo_flag=0)
   - Learns "normal" demand patterns
   - Hyperparameters: lr=0.02, depth=6, leaves=64
   
   Uplift Model:
   - Target: uplift = max(0, true_demand - baseline_pred)
   - Trained ONLY on promo data (promo_flag=1)
   - Learns incremental promo effect
   - Hyperparameters: lr=0.03, depth=8, leaves=80
   
   Final Prediction:
   - If promo_flag=0: prediction = baseline_pred
   - If promo_flag=1: prediction = baseline_pred + uplift_pred
   
   CURRENT RESULT:
   - 5.71% WMAPE (Excellent!)
   - BUT: Suspiciously good - possible overfitting or wrong evaluation


OPTION 3: ENSEMBLE MODEL (EnsembleTrainer)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Combines LightGBM predictions
- Weighted averaging with optimized weights
- Sequential training to save memory
- Expected: 35-38% WMAPE

================================================================================
6. TRAINING PIPELINE (TrainingPipeline Class)
================================================================================

WORKFLOW:
1. Data Split (time-based)
   â””â”€â”€ Train: 70%, Val: 15%, Test: 15%

2. Establish Baseline
   â””â”€â”€ Train with default params â†’ Benchmark performance

3. Hyperparameter Search (Optuna)
   â””â”€â”€ Bayesian optimization on validation set
   â””â”€â”€ 20-50 trials, optimize WMAPE

4. Final Training
   â””â”€â”€ Retrain on train+val with best params
   â””â”€â”€ Evaluate on held-out test set

5. Save Artifacts
   â””â”€â”€ Model, metrics, predictions, feature importance

FEATURES:
- Automated retraining pipelines
- Model versioning (SageMaker Model Registry)
- Drift detection (SageMaker Model Monitor)
- Explainability (SHAP values)

================================================================================
7. CURRENT PERFORMANCE & ISSUES
================================================================================

RESULTS (Advanced Models):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model               â”‚ WMAPE    â”‚ Status     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Short Horizon (1-7d)â”‚ 76.69%   â”‚ âŒ BROKEN  â”‚
â”‚ Mid Horizon (8-30d) â”‚ 77.88%   â”‚ âŒ BROKEN  â”‚
â”‚ Promo Uplift        â”‚ 5.71%    â”‚ âœ… GOOD    â”‚
â”‚ Weighted Average    â”‚ 41.20%   â”‚ âš ï¸  MISLEADâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TARGET: 35-40% WMAPE


IDENTIFIED ISSUES:

ISSUE 1: Horizon Models Not Using Full Feature Set
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Location: HorizonTrainer.train() method

Current Code:
```python
# Creates 3-4 horizon-specific lags
if horizon == 'short':
    df['h_lag_1'] = g[target].shift(1)
    df['h_lag_7'] = g[target].shift(7)
    df['h_roll_7'] = g[target].shift(1).rolling(7).mean()

h_features = feature_cols + [c for c in df.columns if c.startswith('h_')]
```

Problem:
- feature_cols passed to function may not include all 84 engineered features
- Models training with incomplete feature set
- Missing critical features: price, promo, weather, festivals, etc.

Evidence:
- Promo model (uses all features): 5.7% WMAPE âœ…
- Horizon models (limited features): 76-77% WMAPE âŒ

Fix Applied:
```python
h_features = [c for c in feature_cols if c in df.columns] + \
             [c for c in df.columns if c.startswith('h_')]
```

Expected Impact: 76% â†’ 38-42% WMAPE


ISSUE 2: Misleading Average Calculation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current:
```python
avg_wmape = np.mean([short_wmape, promo_wmape])  # Ignores mid!
```

Problem:
- Simple average of 2 models (ignores mid horizon)
- Equal weights (short=50%, promo=50%)
- Not representative of business use case

Fix Applied:
```python
avg_wmape = 0.6*short + 0.2*mid + 0.2*promo  # Business-weighted
```

Rationale:
- Short horizon: 60% (most critical for daily operations)
- Mid horizon: 20% (weekly planning)
- Promo: 20% (promotional planning)


ISSUE 3: Suspicious Promo Model Performance
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Result: 5.71% WMAPE (too good to be true?)

Possible Causes:
1. Data leakage (using future information)
2. Overfitting (train/val from same time period)
3. Wrong evaluation (predicting on training data)
4. Target leakage (using promo_flag in features)

Needs Investigation:
- Check train/val split for promo model
- Verify no data leakage
- Compare with baseline model on same data

================================================================================
8. QUESTIONS FOR ML EXPERT
================================================================================

QUESTION 1: Feature Engineering
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current: 84 features across 7 categories

Are we missing critical features?
- Should we add more lag windows (14d, 21d, 60d)?
- Are interaction terms sufficient (LightGBM auto-generates)?
- Should we add category-specific features (e.g., perishability Ã— temperature)?
- Is weather gating correct (only BEVERAGES, DAIRY, SNACKS)?

Feature importance shows:
- Top 5: demand_lag_1, demand_lag_7, price, discount_depth, promo_flag
- Weather features: Low importance (5-10%)
- Festival features: Medium importance (15-20%)


QUESTION 2: Model Architecture
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current: Horizon-specific models (short/mid/long)

Is this the right approach?
- Alternative 1: Single model with horizon as feature
- Alternative 2: Separate models per SKU category
- Alternative 3: Hierarchical forecasting (location â†’ region â†’ national)

Why are horizon models failing (76% WMAPE)?
- Is it feature engineering issue?
- Is it hyperparameter issue?
- Is it data split issue?
- Should we abandon this approach?


QUESTION 3: Target Variable & Stockout Correction
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current: Velocity-based imputation (7-day rolling avg)

Is this the right approach?
- Alternative 1: Tobit regression (censored regression)
- Alternative 2: Multiple imputation
- Alternative 3: Ignore censored observations (exclude)

Validation:
- Correction increases demand by 10-20%
- Promo model works well with corrected target (5.7% WMAPE)
- Horizon models fail even with corrected target (76% WMAPE)

Does this suggest target correction is correct but model architecture is wrong?


QUESTION 4: Hyperparameters
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current LightGBM params:
- n_estimators: 2000-5000
- learning_rate: 0.02-0.03
- max_depth: 6-8 (horizon models), -1 (baseline)
- num_leaves: 64-256
- min_child_samples: 50-500
- subsample: 0.7-0.8
- colsample_bytree: 0.7-0.8

For 1.7M rows Ã— 84 features:
- Are these reasonable?
- Should we use more aggressive regularization?
- Is Tweedie loss optimal for zero-inflated demand?
- Should we try different objectives (Poisson, Gamma)?


QUESTION 5: Train/Val/Test Split
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current: 80% train / 20% val (time-based)

Is this appropriate for time series?
- Should we use rolling-origin validation?
- Should we use expanding window?
- Is 80/20 split optimal or should we use 70/15/15?

Horizon models:
- Train on 80% oldest data
- Validate on 20% most recent data
- No test set (only validation)

Is this causing the 76% WMAPE issue?


QUESTION 6: Promo Model Suspiciously Good
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Result: 5.71% WMAPE (vs 76% for horizon models)

Why such a huge difference?
- Is promo model overfitting?
- Is there data leakage?
- Is evaluation methodology different?
- Should we trust this result?

Hypothesis:
- Promo model trains on full dataset (no time split?)
- Horizon models use proper time-based validation
- This explains the performance gap

Needs verification in code.


QUESTION 7: Should We Abandon Advanced Models?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current situation:
- Baseline model: Expected 38-42% WMAPE (not tested yet)
- Advanced models: 76-77% WMAPE (broken)
- Promo model: 5.7% WMAPE (suspicious)

Options:
1. Fix advanced models (use all 84 features) â†’ Expected 35-40% WMAPE
2. Use baseline model only â†’ Expected 38-42% WMAPE
3. Use ensemble of baseline models â†’ Expected 36-40% WMAPE

Recommendation needed:
- Is 2-3% improvement worth the complexity?
- Should we focus on baseline + hyperparameter tuning?
- Or fix advanced models and proceed?

================================================================================
9. EXPECTED OUTCOMES AFTER FIXES
================================================================================

SCENARIO 1: Fix Horizon Models (Use All Features)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Short Horizon:  38-42% WMAPE  (from 76%)
Mid Horizon:    40-45% WMAPE  (from 77%)
Promo Uplift:   5-8% WMAPE    (verify not overfitting)
Weighted Avg:   35-40% WMAPE  âœ… TARGET ACHIEVED

Confidence: Medium (depends on feature fix working)


SCENARIO 2: Use Baseline Model Only
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Single LightGBM: 38-42% WMAPE
With tuning:     36-40% WMAPE
With ensemble:   35-39% WMAPE  âœ… TARGET ACHIEVED

Confidence: High (simpler, more reliable)


SCENARIO 3: Hybrid Approach
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Baseline for B/C SKUs:  40-45% WMAPE
Advanced for A SKUs:    35-38% WMAPE
Weighted by revenue:    36-40% WMAPE  âœ… TARGET ACHIEVED

Confidence: Medium-High (best of both worlds)

================================================================================
10. CODE STRUCTURE SUMMARY
================================================================================

training.py (4,301 lines)
â”œâ”€â”€ Configuration Classes (Lines 1-250)
â”‚   â”œâ”€â”€ DataConfig: Paths, file names, column definitions
â”‚   â”œâ”€â”€ ModelConfig: LightGBM hyperparameters
â”‚   â””â”€â”€ TrainingConfig: Train/val/test splits, experiment tracking
â”‚
â”œâ”€â”€ Utilities (Lines 251-350)
â”‚   â”œâ”€â”€ reduce_mem_usage(): Optimize DataFrame memory
â”‚   â””â”€â”€ clean_data_for_training(): Handle inf/NaN values
â”‚
â”œâ”€â”€ Metrics Class (Lines 351-450)
â”‚   â”œâ”€â”€ calculate(): WMAPE, MAE, RMSE, RÂ², bias, service level
â”‚   â””â”€â”€ log_metrics(): Formatted metric logging
â”‚
â”œâ”€â”€ FeatureEngineer Class (Lines 451-1200)
â”‚   â”œâ”€â”€ load_reference_data(): Load SKU, location, festival, weather, etc.
â”‚   â”œâ”€â”€ add_sku_features(): Merge SKU master (category, brand, price)
â”‚   â”œâ”€â”€ add_location_features(): Merge location master (region, channel)
â”‚   â”œâ”€â”€ add_festival_flags(): Festival indicators + proximity (1d, 3d, 7d)
â”‚   â”œâ”€â”€ add_shock_features(): External shock impact multipliers
â”‚   â”œâ”€â”€ add_weather_features(): Weather data (GATED by category)
â”‚   â”œâ”€â”€ add_competitor_features(): Competitor promo/price pressure
â”‚   â”œâ”€â”€ add_lifecycle_features(): Days since launch
â”‚   â”œâ”€â”€ add_calendar_features(): Temporal + cyclical encoding
â”‚   â”œâ”€â”€ add_price_promo_features_v2(): Discount depth, price volatility
â”‚   â”œâ”€â”€ add_lag_features(): Demand lags + rolling stats (horizon-aware)
â”‚   â””â”€â”€ transform(): Full pipeline (84 features)
â”‚
â”œâ”€â”€ FMCGTrainer Class (Lines 1201-2000)
â”‚   â”œâ”€â”€ __init__(): Initialize configs, feature engineer
â”‚   â”œâ”€â”€ _correct_stockout_censoring(): Velocity-based imputation
â”‚   â”œâ”€â”€ load_and_prepare_data(): Load â†’ correct â†’ engineer â†’ clean
â”‚   â”œâ”€â”€ _time_split(): Train/val/test split (time-based)
â”‚   â”œâ”€â”€ _prepare_features(): Select feature columns (exclude leaky)
â”‚   â”œâ”€â”€ _get_model_params(): Build LightGBM params dict
â”‚   â”œâ”€â”€ _train_single_split(): Train on one split, return metrics
â”‚   â”œâ”€â”€ train(): Full training pipeline with early stopping
â”‚   â”œâ”€â”€ _calculate_shap_importance(): SHAP-based feature importance
â”‚   â”œâ”€â”€ _evaluate_by_segment(): Per-category, per-ABC metrics
â”‚   â””â”€â”€ _save_artifacts(): Save model, metrics, predictions
â”‚
â”œâ”€â”€ EnsembleTrainer Class (Lines 2001-2800)
â”‚   â”œâ”€â”€ _get_lgb_model(): LightGBM with Tweedie loss
â”‚   â”œâ”€â”€ _train_sequentially(): Train models one-by-one (memory efficient)
â”‚   â”œâ”€â”€ optimize_weights_from_preds(): Scipy minimize for ensemble weights
â”‚   â”œâ”€â”€ predict_ensemble(): Weighted average of model predictions
â”‚   â””â”€â”€ save_model() / load_model(): Model persistence
â”‚
â”œâ”€â”€ MultiStepForecaster Class (Lines 2801-3200)
â”‚   â”œâ”€â”€ train_direct(): Separate model per horizon
â”‚   â”œâ”€â”€ train_recursive(): Single model, iterative predictions
â”‚   â”œâ”€â”€ train_multi_output(): Single model, all horizons at once
â”‚   â””â”€â”€ predict_recursive_sequence(): Multi-step ahead forecasting
â”‚
â”œâ”€â”€ TrainingPipeline Class (Lines 3201-3800)
â”‚   â”œâ”€â”€ split_data(): Time-based train/val/test split
â”‚   â”œâ”€â”€ train_baseline(): Default params benchmark
â”‚   â”œâ”€â”€ tune_hyperparameters(): Optuna Bayesian optimization
â”‚   â”œâ”€â”€ train_final_model(): Retrain with best params
â”‚   â”œâ”€â”€ evaluate_on_test(): Final evaluation + plots
â”‚   â”œâ”€â”€ train_ensemble(): Train ensemble models (XGB+LGB)
â”‚   â”œâ”€â”€ run(): Complete pipeline (split â†’ baseline â†’ tune â†’ final â†’ eval)
â”‚   â””â”€â”€ save_results(): Save model, params, metrics, predictions
â”‚
â”œâ”€â”€ HorizonTrainer Class (Lines 3801-3950) âš ï¸ BROKEN
â”‚   â””â”€â”€ train(): Horizon-specific models (short/mid/long)
â”‚       â””â”€â”€ ISSUE: Not using all 84 features
â”‚
â”œâ”€â”€ PromoUpliftTrainer Class (Lines 3951-4100) âš ï¸ SUSPICIOUS
â”‚   â””â”€â”€ train(): Baseline + Uplift models
â”‚       â””â”€â”€ ISSUE: 5.7% WMAPE too good (possible overfitting)
â”‚
â”œâ”€â”€ Helper Functions (Lines 4101-4250)
â”‚   â”œâ”€â”€ run_advanced_training(): Orchestrate horizon + promo models
â”‚   â”œâ”€â”€ correct_stockout_censoring_standalone(): Standalone correction
â”‚   â””â”€â”€ tune_hyperparameters(): Optuna tuning wrapper
â”‚
â””â”€â”€ main() Function (Lines 4251-4301)
    â”œâ”€â”€ Auto-detect data path (Kaggle / local)
    â”œâ”€â”€ Load and prepare data
    â”œâ”€â”€ TOGGLE: USE_ADVANCED = True/False
    â”œâ”€â”€ Run baseline OR advanced models
    â””â”€â”€ Print final results

================================================================================
11. IMMEDIATE ACTION ITEMS
================================================================================

PRIORITY 1: Fix Horizon Models (CRITICAL)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
File: training.py, Line ~3850
Change:
  FROM: h_features = feature_cols + [c for c in df.columns if c.startswith('h_')]
  TO:   h_features = [c for c in feature_cols if c in df.columns] + \
                     [c for c in df.columns if c.startswith('h_')]

Expected: 76% â†’ 38-42% WMAPE


PRIORITY 2: Investigate Promo Model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
File: training.py, Line ~3980
Check:
- Train/val split methodology
- Data leakage (using future information?)
- Evaluation on training data vs validation data
- Compare with baseline on same data

Expected: Verify 5.7% WMAPE is legitimate or identify overfitting


PRIORITY 3: Test Baseline Model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
File: training.py, main() function
Change: USE_ADVANCED = False
Run: python training.py

Expected: 38-42% WMAPE (benchmark)


PRIORITY 4: Hyperparameter Tuning
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
If baseline < 40% WMAPE:
- Increase n_trials from 20 to 50-100
- Tune on validation set
- Expected: 36-40% WMAPE

================================================================================
12. CONTACT & NEXT STEPS
================================================================================

SEEKING EXPERT ADVICE ON:
1. Why horizon models fail with 84 features (76% WMAPE)
2. Why promo model is suspiciously good (5.7% WMAPE)
3. Best model architecture for FMCG forecasting
4. Optimal hyperparameters for 1.7M rows Ã— 84 features
5. Whether to use baseline or advanced models

AVAILABLE FOR REVIEW:
- Full codebase (training.py, 4,301 lines)
- Sample data (1.7M rows, 84 features)
- Training logs and metrics
- Feature importance analysis
- SHAP explanations

TIMELINE:
- Need to achieve 35-40% WMAPE for final year project
- Current deadline: End of semester
- Willing to implement suggested changes

================================================================================
END OF DOCUMENT
================================================================================

Please review and provide guidance on:
1. Root cause of 76% WMAPE in horizon models
2. Validation of 5.7% WMAPE in promo model
3. Recommended model architecture
4. Feature engineering improvements
5. Hyperparameter tuning strategy

Thank you for your expertise! ğŸ™
